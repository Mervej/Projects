User -> Gateway -> load balancers -> web server -> cache database -> database
--> apis 
create(long_url, api_key, custom_url) - return short url
get(short_url) - redirect with response 302 - “HTTP 302 Redirect” status is sent back to the browser instead of “HTTP 301 Redirect”. A 301 redirect means that 
the page has permanently moved to a new location. A 302 redirect means that the move is only temporary

--> database 
user - id, active, name, email, created_at
url - short_url, ling_url, user_id, created_at
MongoDB supports distributing data across multiple machines using shards. Since we have to support large data sets and high throughput, we can leverage 
sharding feature of MongoDB. It automatically computes hashes(using tiny url) while resolving queries and facilitates even data distribution among shards
MongoDB supports transaction for single docuement using hash based sharad key and use putIfAbsent 

--> shortening algo
encoding - base 62 are [0–9][a-z][A-Z]
URL with length 5, will give 62⁵ = ~916 Million URLs, URL with length 6, will give 62⁶ = ~56 Billion URLs, URL with length 7, will give 62⁷ = ~3500 Billion URLs
since we req 120 bil, we'll need min of 7 char

Questions - 
1. Lenght of the URL - (16 char)
2. Will the URL ever expire - No
3. Custom URL allowed - Yes
4. How many req per month - 100 mil
5. Analytics to be provider like most visited url etc

Service/Functional requirements -
1. should be able to create shortened URL, 2. short url should redirect to the main url, 3. shorted url should be as small as possible
4. user can create custom url with max lenght - 16, 5. serivce should collect metrics like most clicked, 6. short url created should be there for lifetime

Non functional req -
1. Service should be up and running all time
2. Url generation should fast and also redirections
3. should expose apis to be integrated by 3rd parties

Traffic and space req -  
assuming 200:1 read/write ratio
-no of url gen in 1 month = 100 * 10^6
-per sec = (100 * 10^6)/(3600*24*30) = 40 
40*200:40 read/write ratio per sec

Storage - 
Assuming lifetime - 100 years & size of url(row record) - 500 bytes
- records = (100*12) * (100 * 10^6)
- total size = (100*12) * (100 * 10^6) * 500 = 50TB

Caching - 
80:20 (80% req are for 20% of the data)
read req per day -> 8000 * 86400 = ~700 mil
to cache 20% = .2 * 700*10^6 * 500 = 70 gb

